{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Install missing dependencies ---\n",
        "!pip install -q ultralytics\n",
        "!pip install -q deep_sort_realtime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf1_bBlnZucY",
        "outputId": "3869a6e4-71c8-4808-a2f0-b93211c48d05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=r\".*torch\\.cuda\\.amp\\.autocast.*deprecated.*\",\n",
        "    category=FutureWarning\n",
        ")"
      ],
      "metadata": {
        "id": "c30oiTOsnfRl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "e3WvHvJSnjpT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_INPUT_PATH  = '/content/2863232-uhd_3840_2160_30fps.mp4'\n",
        "VIDEO_OUTPUT_PATH = 'output_tracked_yolo8.mp4'\n"
      ],
      "metadata": {
        "id": "5U_TO15BnoT_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIDENCE_THRES = 0.3\n",
        "\n",
        "TRACK_COLORS = [\n",
        "    (255, 0, 0),     # blue-ish\n",
        "    (0, 255, 0),     # green\n",
        "    (0, 0, 255),     # red\n",
        "    (255, 255, 0),   # cyan\n",
        "    (255, 0, 255),   # magenta\n",
        "    (0, 255, 255),   # yellow\n",
        "]"
      ],
      "metadata": {
        "id": "qhkZ6CV2onby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load YOLOv8 model\n"
      ],
      "metadata": {
        "id": "dsxMmv0jotWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8s.pt')\n",
        "model.fuse()\n",
        "model.conf = CONFIDENCE_THRES\n"
      ],
      "metadata": {
        "id": "ncLbQaZDop6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#  Open video input\n",
        "cap = cv2.VideoCapture(VIDEO_INPUT_PATH)\n",
        "if not cap.isOpened():\n",
        "    raise IOError(f\"Cannot open video: {VIDEO_INPUT_PATH}\")\n",
        "\n",
        "# Prepare video writer\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(VIDEO_OUTPUT_PATH, fourcc, fps, (width, height))\n",
        "\n",
        "# Dictionary for saving track trajectories\n",
        "trajectories = {}\n",
        "\n",
        "# --- Processing loop ---\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # End of video\n",
        "\n",
        "    # A. Use YOLOv8 tracker\n",
        "    results = model.track(source=frame, persist=True, verbose=False)[0]\n",
        "\n",
        "    # B. Process YOLOv8 tracking results\n",
        "    if results and results.boxes is not None:\n",
        "        boxes = results.boxes\n",
        "        for box in boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            if cls != 0:  # Only 'person' class\n",
        "                continue\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            track_id = int(box.id[0]) if box.id is not None else -1\n",
        "            if track_id == -1:\n",
        "                continue\n",
        "\n",
        "            cx, cy = (x1 + x2) // 2, y2\n",
        "\n",
        "            # Save trajectory point\n",
        "            trajectories.setdefault(track_id, []).append((cx, cy))\n",
        "\n",
        "            # Draw bounding box and ID\n",
        "            color = TRACK_COLORS[track_id % len(TRACK_COLORS)]\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "            cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    # C. Draw trajectories\n",
        "    for track_id, pts in trajectories.items():\n",
        "        color = TRACK_COLORS[track_id % len(TRACK_COLORS)]\n",
        "        for i in range(1, len(pts)):\n",
        "            cv2.line(frame, pts[i - 1], pts[i], color, 3)\n",
        "\n",
        "    # D. Save output frame\n",
        "    out.write(frame)\n",
        "\n",
        "# --- Cleanup ---\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(f\" Processing complete. Output saved to {VIDEO_OUTPUT_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFBvViecc2ef",
        "outputId": "70a12aea-c032-4919-fe37-022be9cd6b6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
            " Processing complete. Output saved to output_tracked_yolo8.mp4\n"
          ]
        }
      ]
    }
  ]
}